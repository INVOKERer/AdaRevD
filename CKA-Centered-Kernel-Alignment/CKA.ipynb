{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import cca_core\n",
    "from CKA import linear_CKA, kernel_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA, between X and Y: 0.4080416615691328\n",
      "Linear CKA, between X and X: 1.0000000000000002\n",
      "RBF Kernel CKA, between X and Y: 0.5327389546914577\n",
      "RBF Kernel CKA, between X and X: 1.0\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(100, 64)\n",
    "Y = np.random.randn(100, 64)\n",
    "\n",
    "print('Linear CKA, between X and Y: {}'.format(linear_CKA(X, Y)))\n",
    "print('Linear CKA, between X and X: {}'.format(linear_CKA(X, X)))\n",
    "\n",
    "print('RBF Kernel CKA, between X and Y: {}'.format(kernel_CKA(X, Y)))\n",
    "print('RBF Kernel CKA, between X and X: {}'.format(kernel_CKA(X, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Example of CKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minist layers are: 784(input)--500--500--10(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shapes (500, 10000) (500, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Load up second hidden layer of MNIST networks and compare\n",
    "with open(\"model_activations/MNIST/model_0_lay01.p\", \"rb\") as f:\n",
    "    acts1 = pickle.load(f)\n",
    "with open(\"model_activations/MNIST/model_1_lay01.p\", \"rb\") as f:\n",
    "    acts2 = pickle.load(f)\n",
    "    \n",
    "print(\"activation shapes\", acts1.shape, acts2.shape)\n",
    "\n",
    "#results = cca_core.get_cca_similarity(acts1, acts2, epsilon=1e-10, verbose=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA: 0.8539226154965\n",
      "RBF Kernel: 0.8674208076036767\n"
     ]
    }
   ],
   "source": [
    "# The problem of CKA: time-consuming with large data points\n",
    "print('Linear CKA: {}'.format(linear_CKA(acts1.T, acts2.T)))\n",
    "print('RBF Kernel: {}'.format(kernel_CKA(acts1.T, acts2.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of CCA for the same feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CCA similarity 0.45669867603921466\n"
     ]
    }
   ],
   "source": [
    "# similarity index by CCA\n",
    "results = cca_core.get_cca_similarity(acts1, acts2, epsilon=1e-10, verbose=False)\n",
    "print(\"Mean CCA similarity\", np.mean(results[\"cca_coef1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKA for Conv Nets with SVHN\n",
    "SVHN consists of images that are 32 x 32 (height 32, width 32). Our architecture looks like:\n",
    "\n",
    "**conv1(3x3,32 channels)-->maxpool(2x2)-->conv2(3x3,64 channels)-->maxpool(2x2)-->batchnorm-->fc(200)-->fc(10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16, 16, 64) (1000, 16, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "# Load up conv 2 activations from SVHN\n",
    "with gzip.open(\"model_activations/SVHN/model_0_lay03.p\", \"rb\") as f:\n",
    "    acts1 = pickle.load(f)\n",
    "    \n",
    "with gzip.open(\"model_activations/SVHN/model_1_lay03.p\", \"rb\") as f:\n",
    "    acts2 = pickle.load(f)\n",
    "\n",
    "print(acts1.shape, acts2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Pool for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 64) (1000, 64)\n"
     ]
    }
   ],
   "source": [
    "avg_acts1 = np.mean(acts1, axis=(1,2))\n",
    "avg_acts2 = np.mean(acts2, axis=(1,2))\n",
    "print(avg_acts1.shape, avg_acts2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA: 0.9241440273864195\n",
      "RBF Kernel CKA: 0.9197327226169598\n",
      "Mean CCA similarity 0.6382306681306912\n"
     ]
    }
   ],
   "source": [
    "# CKA\n",
    "print('Linear CKA: {}'.format(linear_CKA(avg_acts1, avg_acts2)))\n",
    "print('RBF Kernel CKA: {}'.format(kernel_CKA(avg_acts1, avg_acts2)))\n",
    "\n",
    "# CCA\n",
    "a_results = cca_core.get_cca_similarity(avg_acts1.T, avg_acts2.T, epsilon=1e-10, verbose=False)\n",
    "print(\"Mean CCA similarity\", np.mean(a_results[\"cca_coef1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolate for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of first conv (1000, 16, 16, 64) shape of second conv (1000, 8, 8, 64)\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(\"./model_activations/SVHN/model_1_lay04.p\", \"rb\") as f:\n",
    "    pool2 = pickle.load(f)\n",
    "    \n",
    "print(\"shape of first conv\", acts1.shape, \"shape of second conv\", pool2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neilyuan/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/neilyuan/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape (1000, 16, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "num_d, h, w, _ = acts1.shape\n",
    "num_c = pool2.shape[-1]\n",
    "pool2_interp = np.zeros((num_d, h, w, num_c))\n",
    "\n",
    "for d in range(num_d):\n",
    "    for c in range(num_c):\n",
    "        # form interpolation function\n",
    "        idxs1 = np.linspace(0, pool2.shape[1],\n",
    "                            pool2.shape[1],\n",
    "                            endpoint=False)\n",
    "        idxs2 = np.linspace(0, pool2.shape[2],\n",
    "                            pool2.shape[2],\n",
    "                            endpoint=False)\n",
    "        arr = pool2[d,:,:,c]\n",
    "        f_interp = interpolate.interp2d(idxs1, idxs2, arr)\n",
    "        \n",
    "        # creater larger arr\n",
    "        large_idxs1 = np.linspace(0, pool2.shape[1],\n",
    "                            acts1.shape[1],\n",
    "                            endpoint=False)\n",
    "        large_idxs2 = np.linspace(0, pool2.shape[2],\n",
    "                            acts1.shape[2],\n",
    "                            endpoint=False)\n",
    "        \n",
    "        pool2_interp[d, :, :, c] = f_interp(large_idxs1, large_idxs2)\n",
    "\n",
    "print(\"new shape\", pool2_interp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CCA similarity 0.3573426816272488\n"
     ]
    }
   ],
   "source": [
    "num_datapoints, h, w, channels = acts1.shape\n",
    "f_acts1 = acts1.reshape((num_datapoints*h*w, channels))\n",
    "\n",
    "num_datapoints, h, w, channels = pool2_interp.shape\n",
    "f_pool2 = pool2_interp.reshape((num_datapoints*h*w, channels))\n",
    "\n",
    "# CCA\n",
    "f_results = cca_core.get_cca_similarity(f_acts1.T[:,::5], f_pool2.T[:,::5], epsilon=1e-10, verbose=False)\n",
    "print(\"Mean CCA similarity\", np.mean(f_results[\"cca_coef1\"]))\n",
    "\n",
    "\n",
    "# CKA\n",
    "#print('Linear CKA: {}'.format(linear_CKA(f_acts1, f_pool2)))      # the shape is too large for CKA\n",
    "#print('RBF Kernel CKA: {}'.format(kernel_CKA(f_acts1, f_pool2)))  # the shape is too large for CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256000, 64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_acts1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
